{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagenerator import DataGen\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy as sc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chi_sq_dist(X):\n",
    "    X_1 = tf.expand_dims(X, 1)\n",
    "    X_2 = tf.expand_dims(X, 0)\n",
    "\n",
    "    epsilon = tf.constant(0.000001)\n",
    "    \n",
    "    return 0.5 * tf.reduce_sum(tf.squared_difference(X_1, X_2) / (X_1+X_2 + epsilon), 2)\n",
    "\n",
    "def chi_sq_nn(X):\n",
    "    dist = chi_sq_dist(X)\n",
    "    return np.argsort(np.abs(dist),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "#X, y = DataGen.gauss(100, 3)\n",
    "#X, y = DataGen.moons(100,10)\n",
    "X, y = DataGen.circle(100,0.1)\n",
    "print(X.shape)\n",
    "N = X.shape[0]\n",
    "dims = X.shape[1]\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier(n_neighbors=N, algorithm='brute')\n",
    "knc.fit(X, y)\n",
    "\n",
    "#dist, nearest_points = knc.kneighbors(X, N, return_distance= True)\n",
    "#impostors = knc.kneighbors(X, N, return_distance= False)\n",
    "nearest_points = chi_sq_nn(X.astype('float32'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Same Class Neighbors - Automatic v2.0\n",
    "nn = np.zeros((N*K,2), dtype=np.int)\n",
    "for i in range(N):\n",
    "    tmp = nearest_points[i]\n",
    "    idx = [elem for elem in tmp if elem in np.where(y==y[i])[0]]\n",
    "    nn[i::N,1] = idx[1:K+1]\n",
    "    nn[i::N,0] = np.repeat(idx[0], K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opposite Class Neighbors - Automatic v2.0\n",
    "im = np.zeros((N*K,2), dtype=np.int)\n",
    "for i in range(N):\n",
    "    tmp = nearest_points[i]\n",
    "    idx = [elem for elem in tmp if elem in np.where(y!=y[i])[0]]\n",
    "    im[i::N,1] = idx[1:K+1]\n",
    "    im[i::N,0] = np.repeat(idx[0], K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16f80163898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_func(X,y):\n",
    "    classes = np.unique(y)\n",
    "    plt.axis('equal')\n",
    "    for i in classes:\n",
    "        plt.plot(X[y==i,0],X[y==i,1],'.')\n",
    "    #plt.show()\n",
    "\n",
    "t = 2\n",
    "print(y[t])\n",
    "plot_func(X,y)\n",
    "plt.plot(X[int(nn[t,0]),0],X[int(nn[t,0]),1],'x')\n",
    "plt.plot(X[nn[t,1:].astype(np.int),0],X[nn[t,1:].astype(np.int),1],'*')\n",
    "plt.plot(X[im[t,:].astype(np.int),0],X[im[t,:].astype(np.int),1],'*')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(X, L):\n",
    "    X_bar = tf.cast(L @ X, tf.float32)\n",
    "    D = chi_sq_dist(X_bar)\n",
    "    pull_term = tf.gather_nd(D, nn) # (N*K, 1) where each element \n",
    "    D_tn = tf.gather_nd(D, im[:,:2]) # FIXME see https://github.com/SkafteNicki/Deep_LMNN/blob/master/dlmnn/helper/tf_funcs.py#L137\n",
    "    D_im = tf.gather_nd(D, im[:,:2]) # FIXME\n",
    "    pull_loss = tf.reduce_sum(pull_term)\n",
    "    push_loss = tf.reduce_sum(margin + D_tn - D_im)\n",
    "\n",
    "    loss = pull_loss + mu * push_loss\n",
    "    return loss\n",
    "\n",
    "def grad(X, L):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(X, L)\n",
    "    return tape.gradient(loss_value, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(400.03522, shape=(), dtype=float32)\n",
      "tf.Tensor(405.31015, shape=(), dtype=float32)\n",
      "tf.Tensor(148.61406, shape=(), dtype=float32)\n",
      "tf.Tensor(3810424.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3820768.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3812947.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3807512.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3802908.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3798850.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3795200.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3791872.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3788809.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3785968.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3783319.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3780835.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3778499.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3776291.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3774198.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3772208.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3770312.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3768501.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3766767.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3765103.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3763506.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3761967.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3760485.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3759054.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3757671.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3756333.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3755038.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3753781.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3752561.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3751375.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3750222.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3749099.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3748004.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3746936.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3745894.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3744876.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3743880.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3742905.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3741950.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3741014.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3740096.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3739195.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3738310.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3737440.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3736585.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3735743.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3734915.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3734098.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3733294.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3732500.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3731717.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3730945.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3730182.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3729428.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3728683.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3727946.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3727217.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3726496.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3725783.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3725076.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3724375.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3723682.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3722994.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3722312.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3721636.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3720966.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3720300.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3719639.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3718984.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3718332.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3717685.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3717043.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3716404.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3715770.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3715139.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3714512.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3713888.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3713268.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3712651.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3712037.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3711426.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3710818.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3710212.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3709610.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3709010.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3708413.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3707818.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3707225.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3706635.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3706047.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3705461.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3704877.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3704295.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3703715.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3703137.8, shape=(), dtype=float32)\n",
      "tf.Tensor(3702561.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3701987.2, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "A = np.eye(N) + 0.01* np.ones((N,N))\n",
    "L = tf.Variable(tf.nn.softmax(A,axis=0))\n",
    "\n",
    "margin = 1\n",
    "mu = 1\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "for _ in range(100):\n",
    "    grads = grad(X, L)\n",
    "    optimizer.apply_gradients(zip([grads], [L]))\n",
    "\n",
    "    print(loss(X, L))\n",
    "\n",
    "#optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(100)])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30],\n",
       "       [76],\n",
       "       [49],\n",
       "       [22],\n",
       "       [84],\n",
       "       [88],\n",
       "       [37],\n",
       "       [35],\n",
       "       [44],\n",
       "       [50],\n",
       "       [30],\n",
       "       [94],\n",
       "       [68],\n",
       "       [33],\n",
       "       [71],\n",
       "       [57],\n",
       "       [61],\n",
       "       [91],\n",
       "       [67],\n",
       "       [94],\n",
       "       [96],\n",
       "       [22],\n",
       "       [ 4],\n",
       "       [30],\n",
       "       [41],\n",
       "       [57],\n",
       "       [10],\n",
       "       [35],\n",
       "       [49],\n",
       "       [56],\n",
       "       [59],\n",
       "       [94],\n",
       "       [56],\n",
       "       [13],\n",
       "       [75],\n",
       "       [ 7],\n",
       "       [57],\n",
       "       [ 6],\n",
       "       [92],\n",
       "       [12],\n",
       "       [75],\n",
       "       [76],\n",
       "       [71],\n",
       "       [75],\n",
       "       [ 8],\n",
       "       [50],\n",
       "       [65],\n",
       "       [75],\n",
       "       [55],\n",
       "       [50],\n",
       "       [49],\n",
       "       [96],\n",
       "       [94],\n",
       "       [56],\n",
       "       [49],\n",
       "       [48],\n",
       "       [77],\n",
       "       [15],\n",
       "       [59],\n",
       "       [30],\n",
       "       [57],\n",
       "       [76],\n",
       "       [91],\n",
       "       [ 4],\n",
       "       [39],\n",
       "       [46],\n",
       "       [76],\n",
       "       [18],\n",
       "       [12],\n",
       "       [44],\n",
       "       [42],\n",
       "       [42],\n",
       "       [99],\n",
       "       [57],\n",
       "       [99],\n",
       "       [47],\n",
       "       [41],\n",
       "       [56],\n",
       "       [ 4],\n",
       "       [91],\n",
       "       [13],\n",
       "       [48],\n",
       "       [96],\n",
       "       [76],\n",
       "       [ 4],\n",
       "       [91],\n",
       "       [56],\n",
       "       [49],\n",
       "       [71],\n",
       "       [92],\n",
       "       [17],\n",
       "       [85],\n",
       "       [10],\n",
       "       [47],\n",
       "       [65],\n",
       "       [ 6],\n",
       "       [82],\n",
       "       [65],\n",
       "       [61],\n",
       "       [72],\n",
       "       [30],\n",
       "       [76],\n",
       "       [49],\n",
       "       [22],\n",
       "       [84],\n",
       "       [88],\n",
       "       [37],\n",
       "       [35],\n",
       "       [44],\n",
       "       [50],\n",
       "       [30],\n",
       "       [94],\n",
       "       [68],\n",
       "       [33],\n",
       "       [71],\n",
       "       [57],\n",
       "       [61],\n",
       "       [91],\n",
       "       [67],\n",
       "       [94],\n",
       "       [96],\n",
       "       [22],\n",
       "       [ 4],\n",
       "       [30],\n",
       "       [41],\n",
       "       [57],\n",
       "       [10],\n",
       "       [35],\n",
       "       [49],\n",
       "       [56],\n",
       "       [59],\n",
       "       [94],\n",
       "       [56],\n",
       "       [13],\n",
       "       [75],\n",
       "       [ 7],\n",
       "       [57],\n",
       "       [ 6],\n",
       "       [92],\n",
       "       [12],\n",
       "       [75],\n",
       "       [76],\n",
       "       [71],\n",
       "       [75],\n",
       "       [ 8],\n",
       "       [50],\n",
       "       [65],\n",
       "       [75],\n",
       "       [55],\n",
       "       [50],\n",
       "       [49],\n",
       "       [96],\n",
       "       [94],\n",
       "       [56],\n",
       "       [49],\n",
       "       [48],\n",
       "       [77],\n",
       "       [15],\n",
       "       [59],\n",
       "       [30],\n",
       "       [57],\n",
       "       [76],\n",
       "       [91],\n",
       "       [ 4],\n",
       "       [39],\n",
       "       [46],\n",
       "       [76],\n",
       "       [18],\n",
       "       [12],\n",
       "       [44],\n",
       "       [42],\n",
       "       [42],\n",
       "       [99],\n",
       "       [57],\n",
       "       [99],\n",
       "       [47],\n",
       "       [41],\n",
       "       [56],\n",
       "       [ 4],\n",
       "       [91],\n",
       "       [13],\n",
       "       [48],\n",
       "       [96],\n",
       "       [76],\n",
       "       [ 4],\n",
       "       [91],\n",
       "       [56],\n",
       "       [49],\n",
       "       [71],\n",
       "       [92],\n",
       "       [17],\n",
       "       [85],\n",
       "       [10],\n",
       "       [47],\n",
       "       [65],\n",
       "       [ 6],\n",
       "       [82],\n",
       "       [65],\n",
       "       [61],\n",
       "       [72],\n",
       "       [30],\n",
       "       [76],\n",
       "       [49],\n",
       "       [22],\n",
       "       [84],\n",
       "       [88],\n",
       "       [37],\n",
       "       [35],\n",
       "       [44],\n",
       "       [50],\n",
       "       [30],\n",
       "       [94],\n",
       "       [68],\n",
       "       [33],\n",
       "       [71],\n",
       "       [57],\n",
       "       [61],\n",
       "       [91],\n",
       "       [67],\n",
       "       [94],\n",
       "       [96],\n",
       "       [22],\n",
       "       [ 4],\n",
       "       [30],\n",
       "       [41],\n",
       "       [57],\n",
       "       [10],\n",
       "       [35],\n",
       "       [49],\n",
       "       [56],\n",
       "       [59],\n",
       "       [94],\n",
       "       [56],\n",
       "       [13],\n",
       "       [75],\n",
       "       [ 7],\n",
       "       [57],\n",
       "       [ 6],\n",
       "       [92],\n",
       "       [12],\n",
       "       [75],\n",
       "       [76],\n",
       "       [71],\n",
       "       [75],\n",
       "       [ 8],\n",
       "       [50],\n",
       "       [65],\n",
       "       [75],\n",
       "       [55],\n",
       "       [50],\n",
       "       [49],\n",
       "       [96],\n",
       "       [94],\n",
       "       [56],\n",
       "       [49],\n",
       "       [48],\n",
       "       [77],\n",
       "       [15],\n",
       "       [59],\n",
       "       [30],\n",
       "       [57],\n",
       "       [76],\n",
       "       [91],\n",
       "       [ 4],\n",
       "       [39],\n",
       "       [46],\n",
       "       [76],\n",
       "       [18],\n",
       "       [12],\n",
       "       [44],\n",
       "       [42],\n",
       "       [42],\n",
       "       [99],\n",
       "       [57],\n",
       "       [99],\n",
       "       [47],\n",
       "       [41],\n",
       "       [56],\n",
       "       [ 4],\n",
       "       [91],\n",
       "       [13],\n",
       "       [48],\n",
       "       [96],\n",
       "       [76],\n",
       "       [ 4],\n",
       "       [91],\n",
       "       [56],\n",
       "       [49],\n",
       "       [71],\n",
       "       [92],\n",
       "       [17],\n",
       "       [85],\n",
       "       [10],\n",
       "       [47],\n",
       "       [65],\n",
       "       [ 6],\n",
       "       [82],\n",
       "       [65],\n",
       "       [61],\n",
       "       [72],\n",
       "       [30],\n",
       "       [76],\n",
       "       [49],\n",
       "       [22],\n",
       "       [84],\n",
       "       [88],\n",
       "       [37],\n",
       "       [35],\n",
       "       [44],\n",
       "       [50],\n",
       "       [30],\n",
       "       [94],\n",
       "       [68],\n",
       "       [33],\n",
       "       [71],\n",
       "       [57],\n",
       "       [61],\n",
       "       [91],\n",
       "       [67],\n",
       "       [94],\n",
       "       [96],\n",
       "       [22],\n",
       "       [ 4],\n",
       "       [30],\n",
       "       [41],\n",
       "       [57],\n",
       "       [10],\n",
       "       [35],\n",
       "       [49],\n",
       "       [56],\n",
       "       [59],\n",
       "       [94],\n",
       "       [56],\n",
       "       [13],\n",
       "       [75],\n",
       "       [ 7],\n",
       "       [57],\n",
       "       [ 6],\n",
       "       [92],\n",
       "       [12],\n",
       "       [75],\n",
       "       [76],\n",
       "       [71],\n",
       "       [75],\n",
       "       [ 8],\n",
       "       [50],\n",
       "       [65],\n",
       "       [75],\n",
       "       [55],\n",
       "       [50],\n",
       "       [49],\n",
       "       [96],\n",
       "       [94],\n",
       "       [56],\n",
       "       [49],\n",
       "       [48],\n",
       "       [77],\n",
       "       [15],\n",
       "       [59],\n",
       "       [30],\n",
       "       [57],\n",
       "       [76],\n",
       "       [91],\n",
       "       [ 4],\n",
       "       [39],\n",
       "       [46],\n",
       "       [76],\n",
       "       [18],\n",
       "       [12],\n",
       "       [44],\n",
       "       [42],\n",
       "       [42],\n",
       "       [99],\n",
       "       [57],\n",
       "       [99],\n",
       "       [47],\n",
       "       [41],\n",
       "       [56],\n",
       "       [ 4],\n",
       "       [91],\n",
       "       [13],\n",
       "       [48],\n",
       "       [96],\n",
       "       [76],\n",
       "       [ 4],\n",
       "       [91],\n",
       "       [56],\n",
       "       [49],\n",
       "       [71],\n",
       "       [92],\n",
       "       [17],\n",
       "       [85],\n",
       "       [10],\n",
       "       [47],\n",
       "       [65],\n",
       "       [ 6],\n",
       "       [82],\n",
       "       [65],\n",
       "       [61],\n",
       "       [72]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[:,::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [2,2], In[1]: [100,2] [Op:MatMul] name: matmul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4cfc72f55d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    969\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2108\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4232\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4233\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4234\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [2,2], In[1]: [100,2] [Op:MatMul] name: matmul/"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "j = 2\n",
    "q = 0\n",
    "p = 0\n",
    "A = np.eye(2) + 0.01*np.ones((2,2))\n",
    "L = tf.nn.softmax(A,axis=0)\n",
    "\n",
    "xbar = L @ X\n",
    "\n",
    "\n",
    "tijp = (xbar[i,p] - xbar[j,p]) / (xbar[i,p] - xbar[j,p])\n",
    "tempsum = 0\n",
    "for l in range(r):\n",
    "    tijl = (xbar[i,l] - xbar[j,l]) / (xbar[i,l] - xbar[j,l])\n",
    "    tempsum += L[l,q]*(tijl*(X[i,q] - X[j,q]) - tijl*tijl*(X[i,q] + X[j,q])/2 )\n",
    "    \n",
    "dCijqp = L[q,p]*( tijp*(X[i,q] - X[j,q]) - tijp*tijp*(X[i,q]+X[j,q])/2 ) - tempsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=336, shape=(2, 100), dtype=float64, numpy=\n",
       "array([[1.18791127, 1.30834811, 0.44020902, 1.37982368, 1.68827717,\n",
       "        1.6618579 , 0.81070595, 0.74902455, 1.13256339, 1.58739523,\n",
       "        1.63455958, 1.38995312, 0.64496808, 0.44560822, 2.02629541,\n",
       "        0.99228199, 0.73284837, 0.84475219, 0.85107218, 1.65599924,\n",
       "        1.30804498, 1.6988241 , 0.87799051, 0.72613272, 1.23476277,\n",
       "        1.28851238, 1.82487118, 1.71362377, 1.5882432 , 1.43668385,\n",
       "        1.1114366 , 0.22716015, 0.52557251, 0.94879152, 1.47565721,\n",
       "        0.79035728, 1.63816184, 0.56193443, 0.51727074, 0.46547239,\n",
       "        1.24091883, 1.20556986, 1.5141785 , 0.54802127, 0.54648409,\n",
       "        0.98007474, 1.79461853, 1.69618968, 0.59960175, 0.59939353,\n",
       "        1.47782718, 1.7655701 , 1.70942627, 1.79550265, 0.53550774,\n",
       "        1.72778874, 0.90758804, 1.72412119, 1.31659464, 1.24515464,\n",
       "        0.44646163, 0.59527393, 1.35897142, 1.67830578, 1.55108744,\n",
       "        0.64275474, 1.07869813, 0.64478262, 0.96398459, 0.75660197,\n",
       "        1.03527196, 1.73501318, 0.31787413, 0.9400711 , 1.84308326,\n",
       "        0.50905284, 0.80715548, 0.51649723, 0.58442187, 1.00898348,\n",
       "        0.39549292, 1.49290696, 1.56824047, 1.5712039 , 1.83151838,\n",
       "        0.65227194, 0.52009834, 0.94506955, 1.70932361, 0.4149586 ,\n",
       "        0.47867792, 0.37275702, 1.91600109, 1.23268441, 0.41618515,\n",
       "        0.74902965, 1.30941135, 1.44267706, 0.46624986, 0.93228769],\n",
       "       [0.65797935, 0.8669217 , 0.3563382 , 1.0191793 , 1.19146686,\n",
       "        1.31668185, 1.53347875, 0.40475928, 1.57666033, 0.89461159,\n",
       "        1.22525737, 1.76914001, 0.60410153, 0.71388954, 1.81964636,\n",
       "        1.55797208, 1.17947879, 1.33867584, 0.53818512, 1.77367878,\n",
       "        1.52388111, 1.54548706, 0.38535519, 0.2671293 , 0.73794523,\n",
       "        0.5829565 , 1.79424446, 1.50099502, 1.76471971, 1.93050969,\n",
       "        1.50993951, 0.50989792, 0.90601328, 1.55320993, 1.9764757 ,\n",
       "        0.36976492, 1.7935012 , 0.48711473, 0.74627189, 1.08323334,\n",
       "        0.73267156, 0.70464222, 1.69082726, 0.30717142, 0.38354022,\n",
       "        0.62832029, 1.7861616 , 1.95652153, 1.11856977, 0.96330899,\n",
       "        0.97574139, 1.37724466, 1.63035894, 1.54812425, 0.65307258,\n",
       "        1.81039275, 0.59208289, 1.76169239, 0.75455874, 0.72024567,\n",
       "        0.32945668, 1.3810781 , 0.88851656, 1.19792705, 1.77173382,\n",
       "        0.62765666, 1.76104312, 1.07520209, 1.64955729, 1.29442773,\n",
       "        0.51374505, 1.65801911, 0.86407148, 1.53489452, 1.41784961,\n",
       "        0.85712478, 1.35959016, 0.46938849, 0.84557821, 0.62051309,\n",
       "        0.3527695 , 0.95180192, 1.27300065, 0.9755796 , 1.41976359,\n",
       "        1.33354818, 0.59865922, 1.62811286, 1.56488521, 0.70421584,\n",
       "        1.00025736, 0.67231939, 1.66027079, 0.69215467, 1.0163537 ,\n",
       "        0.49213495, 1.71422204, 1.72056632, 0.71188832, 1.49112204]])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtf = L @ np.asarray(X).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=300, shape=(), dtype=float64, numpy=1.0901506926524922>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbar[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.contrib.eager.Variable(X, dtype=tf.float32)\n",
    "\n",
    "target_neighbours = tf.zeros((N, K)) #TODO!\n",
    "impostors = tf.zeros((N, K)) #TODO!\n",
    "\n",
    "A = 10 * tf.eye(dims) + 0.01 * tf.ones((dims,dims))\n",
    "# If we do softmax, then according to Yang, A=10*tf.eye(dims) - 5*tf.ones((dims,dims))\n",
    "L = tf.softmax(A, axis=0)\n",
    "\n",
    "chi_dist = chi_sq_dist(L @ X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import additive_chi2_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "additive_chi2_kernel(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = -0.5 * additive_chi2_kernel(X)\n",
    "\n",
    "tape.gradient(loss, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.matmul(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
